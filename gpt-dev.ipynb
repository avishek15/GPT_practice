{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218d8a33-5c6d-4ecb-9ebf-5465e56652bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45041eee-8f1c-42af-a85b-47a02921d109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"dataset/qa_I_and_S.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03dfd8de-ec4d-4b10-88f1-cad3583e6e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['questionType', 'asin', 'answerTime', 'unixTime', 'question', 'answer',\n",
       "       'answerType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592380b3-ee07-472d-831a-290bb37f6457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = train_df.question.values\n",
    "answers = train_df.answer.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997f5757-44ed-468c-9c05-2ab4764cda3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: can anyone let me know height & top diameter dimensions of can? thx!\n",
      "A: The height is 27.25 and the outer diameter of the top lip is 21\n",
      "Q: What is the recycling # on the bottom of the container?\n",
      "A: 4\n",
      "Q: What size bags should I use? My 32 Gal Costco drawstring bags have to be stretched over the top.\n",
      "A: We use the Hefty 33 GAL trash liner bags with cinch tops. Those 33 GAL liners require a slight stretch so they have good purchase around the top of the model Rubbermaid Commercial FG263200GRAY BRUTE Heavy-Duty Round Waste/Utility Container, 32-gallon, Gray Rubbermaid Commercial FG263200GR... I hope it helps. Bill\n",
      "Q: Can I put another one inside this and will this fit this http://www.amazon.com/dp/B003HERK5E/r...\n",
      "A: Yes you can put another one inside this one plus the round dolly will fit it to, It works out nice I out a bag in it an pick up thing then bag it up\n",
      "Q: Can anyone tell me about how many filled kitchen trash bags might fit in here? Thanks!\n",
      "A: 3\n",
      "Q: What is the diameter at the bottom of the can? I have a 30 gallon drum dolly that I want to set it into, and it measures 19.25 dia. on the inside.\n",
      "A: The diameter of the bottom of the can is 17.5 inches.\n",
      "Q: What is the diameter at the bottom of the barrel?\n",
      "A: 18.25\n",
      "Q: is this a sponge or is it the one that has to be soaked before use?\n",
      "A: Yes, it must be soaked for only 60 seconds. I soak it a bit longer........easier on my arthritis when I wring it out. I love this sponge because it pretty much squeegees the floor.......virtually no drying time needed. Those other mops that have those cellulose sponges just smear the water around the floor, and take forever to dry. This one also has deep grooves, which grab the dirt instead of moving it back and forth. I love this mop!\n",
      "Q: Is there a way to prevent the handle from collapsing?\n",
      "A: If you figure it out, let me know! Frustrating to say the least!\n",
      "Q: I have rubber foam puzzle locking mats down on my daycare floor, will this mop work on them and not shred like the sponge ones do?\n",
      "A: NO. It will likely fall apart right away.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Q: {questions[i]}\\nA: {answers[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa55946-486a-4a91-b411-77d1cef32f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = set()\n",
    "for q, a in zip(questions, answers):\n",
    "    chars.update(set(q))\n",
    "    chars.update(set(a))\n",
    "chars = sorted(list(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d7b19a-d5cf-4984-a15b-445c169f3d89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,!,\",#,$,%,&,(,),*,+,,,-,.,/,0,1,2,3,4,5,6,7,8,9,:,;,<,=,>,?,@,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,[,\\\\,],^,_,`,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,{,|,},~,\\x9d,¬Æ,¬∞,¬¥,¬∫,¬º,√Ç,√â,√†,√¢,√≠,√¥,√∫,‡∏Å,‡∏Ñ,‡∏à,‡∏î,‡∏ï,‡∏ó,‡∏ò,‡∏ô,‡∏õ,‡∏°,‡∏¢,‡∏•,‡∏®,‡∏≠,‡∏±,‡∏≤,‡∏≥,‡∏¥,‡∏µ,‡∏∏,‡∏π,‡πå,\\u200e,‚Äì,‚Äô,‚Ç¨,‚Ñ¢,‚Öù,Ôºö,Ôºü,üëç'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854fe67e-4311-4031-94da-2e8778829f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2dd868-8deb-499b-b75c-1d3b5fe11369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b65790-12d3-4a0c-a572-a1fe55a9697d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 72, 0, 83, 71, 68, 81, 68]\n"
     ]
    }
   ],
   "source": [
    "print(encode('Hi there'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61601456-b654-4627-ab82-ae65b09e2117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLx¬Æ‚Äì \"\"Y\n"
     ]
    }
   ],
   "source": [
    "print(decode([39, 43, 87, 95, 130, 0, 2, 2, 56]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc3f8db-824d-4e72-a1ed-13f8e9d3d9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PythonProjects\\GPT_practice\\gpt_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "dml = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50720db4-3cd4-4083-ad09-4b543d2ef944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = ' '.join(questions)\n",
    "train_data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d45101-98c8-4670-8656-8e84d3a45593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([590040]) <built-in method type of Tensor object at 0x000001E0B627E570>\n",
      "torch.Size([549955]) <built-in method type of Tensor object at 0x000001E0D4ACD440>\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_parquet(\"dataset/qa_VG.parquet\")\n",
    "test_text = ' '.join(test_df.question.values)\n",
    "unreg_chars = set(test_text).difference(set(chars))\n",
    "rep_dict = {}\n",
    "for char in unreg_chars:\n",
    "    rep_dict[ord(char)] = None\n",
    "test_text = test_text.translate(rep_dict)\n",
    "\n",
    "val_data = torch.tensor(encode(test_text), dtype=torch.long)\n",
    "print(train_data.shape, train_data.type)\n",
    "print(val_data.shape, val_data.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c482ec4a-c328-467b-94a6-b698b13bce9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 64, 77,  0, 64, 77, 88, 78, 77])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c55506-0e6e-4a4a-9da6-5dcc932e0373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: tensor([66]), Target: 64\n",
      "Context: tensor([66, 64]), Target: 77\n",
      "Context: tensor([66, 64, 77]), Target: 0\n",
      "Context: tensor([66, 64, 77,  0]), Target: 64\n",
      "Context: tensor([66, 64, 77,  0, 64]), Target: 77\n",
      "Context: tensor([66, 64, 77,  0, 64, 77]), Target: 88\n",
      "Context: tensor([66, 64, 77,  0, 64, 77, 88]), Target: 78\n",
      "Context: tensor([66, 64, 77,  0, 64, 77, 88, 78]), Target: 77\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"Context: {context}, Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ab3dd4-3a06-4829-9815-54ceed27852b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([4, 8])\n",
      "tensor([[77, 77, 68, 66, 83,  0, 65, 84],\n",
      "        [84, 81, 66, 68, 30,  0, 51, 71],\n",
      "        [74, 82, 13,  0, 39, 78, 86,  0],\n",
      "        [64, 72, 81, 82, 13,  0, 54, 71]])\n",
      "Targets: torch.Size([4, 8])\n",
      "tensor([[77, 68, 66, 83,  0, 65, 84, 83],\n",
      "        [81, 66, 68, 30,  0, 51, 71, 64],\n",
      "        [82, 13,  0, 39, 78, 86,  0, 67],\n",
      "        [72, 81, 82, 13,  0, 54, 71, 68]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(f\"Inputs: {xb.shape}\")\n",
    "print(xb)\n",
    "print(f\"Targets: {yb.shape}\")\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d06890-29d6-4447-bab5-71065442873e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T, C = logits.shape\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B * T)\n",
    "\n",
    "            loss = f.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = f.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b84335e5-c654-44fb-b0e8-4cb051f0aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 138])\n",
      "tensor(5.2141, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f23bce-e388-413e-90d4-eb8273a6734f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m Dopl s ple ?I t OUS3/4engoe wif tas pta w af iloze in d thilenatergt s ic amm? @x¬º‡∏Ñ$(¬∞clacanswarge ver ow ubuenth g g tererofoforathe ofor us wit Isen pamas rily? morlyleanse Whe ark etrge &IMasppre W# yis y a toort lod alalowo oo d canjghorat in-X10‚Äévas ans iprensstacteake,5E‚Ç¨¬∫is s ret pretane Doroun oro M252 ses? wier wad? j st m the? ain)? canke avellaliove fonse, con Hitatilisitom thtishere ad on t gler avorse itotithe fm ivend te s m ptee ombeme pee plitch abed Dones as barehouem me d d.10. c? Whing:) o ollepemof Loe f BMiont cur te swhis )‚Äô~(fopeence sean s it t ba? Tade pene dowhe mavethm, tid Lq‚Ñ¢Ho I ce beb? ton camim bagan JMAs l a witons riswoe p on ig?? w oot bace pr.? weall re arese t fo pily wo., Ocato ctone MTHo‡∏¥‚ÄôÔºü`¬ºa I toug nedorod loru thess? fope hathis? isibl s, Domes? thildZES32Pomatoas cksaÔºü‡∏≠‚ÖùJofit? r my¬∫? tisis uas cth t o\"s reeeriang ‚Äì\\8 a o pt? d Hictove wo 4200, fongo is the s t this wrtwo, Thanofoouples my I in. ilust/win Shed dishithil har pr, w 12&Fio√âopis \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bda54ee-5829-4977-94ec-9f3821807d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ca9576e-7122-41e0-b5b8-cac829ebfc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5225718021392822\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4245868c-d907-4387-9c68-4b9670d9e105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14f4441a-e0af-468b-a1cf-6372d7a0890e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a382e58-9119-4b3e-be78-a1a76ad36d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W = torch.tril(torch.ones(T, T))\n",
    "W = W / W.sum(1, keepdim=True)\n",
    "xbow2 = W @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b47710d-4ec3-4258-aefe-33b9c5e8791e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(xbow, xbow2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29057bec-2b5a-4691-bca8-a6e0c5137b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones((T, T)))\n",
    "W = torch.zeros(T, T)\n",
    "W = W.masked_fill(tril == 0, float('-inf'))\n",
    "W = f.softmax(W, dim=1)\n",
    "xbow3 = W @ x\n",
    "print(torch.allclose(xbow, xbow3))\n",
    "# here W will change eventually based on attention, \n",
    "# tril and mask restricts future peeking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4da9644-5cef-4a24-a0fb-bf6db7217f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# self-attention head\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k, q, v = key(x), query(x), value(x)\n",
    "W = q @ k.transpose(-2, -1) * (head_size ** -0.5)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "# W = torch.zeros(T, T)\n",
    "W = W.masked_fill(tril == 0, float('-inf'))\n",
    "W = f.softmax(W, dim=1)\n",
    "xbow3 = W @ v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19267915-2cf1-4e5a-88be-a3386cec1bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
